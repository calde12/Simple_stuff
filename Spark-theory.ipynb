{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark introduction\n",
    "\n",
    "The rate of execution per node in Spark remains quite uniform, which indicates very good scaling performances.  \n",
    "Spark streaming is for real-time processing (divided between Streaming and Structured-Streaming).\n",
    "\n",
    "The foundation on which Spark runs are three servers: YARN is a scheduler and Mesos is similar to Redis as \"network\" between tasks.  \n",
    "RDDs are the main programming abstraction.\n",
    "\n",
    "### Spark SQL\n",
    "The querying is done via SQL or HiveQL (a pseudo SQL that runs on MapReduce functionality). You can combine SQL with complex analytics\n",
    "\n",
    "\n",
    "### Spark Streaming\n",
    "Lives parallelly to Spark Core, and has dedicated API. Combined well for batch computation and interactive queries.  \n",
    "If nodes goes down Spark can rebuild computations.\n",
    "\n",
    "\n",
    "### Cluster managers\n",
    "The driver kind of only gives instructions. The code you write get executed on nodes that are who knows how far away.  \n",
    "A JVM is much more like an interpreter.  \n",
    "Spark session is accessed through SparkContext. \n",
    "\n",
    "Spark-Notebook or Zeppelin are notebook application to use Spark.  \n",
    "\n",
    "Spawning an application directly on YARN's Application Master gives you some more fault tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDDs\n",
    "\n",
    "Partitions can have duplicates inside themselves. The data inside is immutable\n",
    "\n",
    "### Transformation of partitions\n",
    "\n",
    "`coalesce(n)` reduces the number of partitions (without shuffle), while `repartition(n)` increases it.  \n",
    "The best is dividing the actual number of partitions by an integer.\n",
    "\n",
    "### Key-values RDDs\n",
    "\n",
    "They have a basic structure (and not a schemaless collections of rows). **Same keys have to be in the same partition**!\n",
    "\n",
    "### Side effects of partitioning\n",
    "\n",
    "The .filter transformation can result in unbalanced partitions for the output RDD.  \n",
    "Imagine data like {name: persons_data}. With `map`, the partition is made again anew: this is because Spark cannot understand that you're assigning the same value to the same key. You have to use `mapValues` because in this way Spark knows that the key stays the same\n",
    "\n",
    "## RDDs VS DataFrame VS DataSets\n",
    "\n",
    "DataFrames may have limited expressiveness; complex transformations are better expressed by RDDs.  \n",
    "User Defined Functions must be executed in child python process; it applies the function not in the Spark executor: moving the data back and forth the executor and the python process takes time (for RDDs).  \n",
    "DataFrames can compress data effectively.\n",
    "\n",
    "DataFrames are a special type of DataSets. With it Sparks detects error before compile time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\")\\\n",
    ".config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdiveconda",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
